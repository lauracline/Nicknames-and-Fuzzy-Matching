{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled26.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOWAxeCSKsJtk77dfSpG+Ck",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lauracline/Nicknames-and-Fuzzy-Matching/blob/master/Nicknames%20and%20Fuzzy%20Matching\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WetER13sDe4K",
        "outputId": "c22ac5bf-2682-48dc-daed-428e41793b32"
      },
      "source": [
        "!pip install fuzzywuzzy\n",
        "!pip install xlsxwriter"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fuzzywuzzy in /usr/local/lib/python3.7/dist-packages (0.18.0)\n",
            "Collecting xlsxwriter\n",
            "  Downloading XlsxWriter-3.0.2-py3-none-any.whl (149 kB)\n",
            "\u001b[K     |████████████████████████████████| 149 kB 11.7 MB/s \n",
            "\u001b[?25hInstalling collected packages: xlsxwriter\n",
            "Successfully installed xlsxwriter-3.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgSi73TaDMRU"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import collections\n",
        "import time\n",
        "from fuzzywuzzy import fuzz"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvg13nCfDN1r",
        "outputId": "a3af1b03-5f88-4d6b-ea93-a3523989da5b"
      },
      "source": [
        "d = {'Customer Name': ['ED SMITH','EDWARD SMITH','JOE DOE','PAT MUELLER','PATRICK MUELLER','LISA DANE', \n",
        "                       'ALEX SMITH', 'SMITH ALEX','DIANA HAYDEN','RUSS PARK','SARA JANE', 'AARON GOMSEY',\n",
        "                       'ARON GOMSEY','KIM CHEN','SCOTT HARRIS','ELIZABETH HURN','LIZ HURN','ROBERT LIN',\n",
        "                       'ANDY ROBERTSON','JORDAN HENDERSON'],\n",
        "     'Customer Address': ['218-KENSINGTON-DETROIT-MI','218-KENSINGTON-DETROIT-MI','SUNPHARMA-NOVI-MI',\n",
        "                          '7650-ASHWOODPARK-DALLAS-TX','7650-ASHWOODPARK-DALLAS-TX','2100-PEBBLEVALE-MIAMI-FL',\n",
        "                          '16-MISSIONSTREET-SANFRANCISCO-CA','16-MISSIONSTREET-SANFRANCISCO-CA','FARM-WOOD-AZ',\n",
        "                          'WEST-CAMBELL-LASVEGAS-NV','9-OAKS-APTS-BUFFALO-NY','11-DNAWAY-REDWOOD-CA',\n",
        "                          '11-DNAWAY-REDWOOD-CA','8-ELMOND-BOLINGBROOK-IL','9024-SOUTHSTREET-MONSEY-NY',\n",
        "                          '53-DOGWOOD-LIVINGSTON-NJ','53-DOGWOOD-LIVINGSTON-NJ','8505-CORONAAVE-BARBERTON-OH',\n",
        "                          '11-PULASKIAVE-EASTSTROUD-PA','161-SUMMITDR-WAUSAU-WI'],\n",
        "     'Customer ID': [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]}\n",
        "\n",
        "df = pd.DataFrame(data=d)\n",
        "print(df.head())"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Customer Name            Customer Address  Customer ID\n",
            "0         ED SMITH   218-KENSINGTON-DETROIT-MI            1\n",
            "1     EDWARD SMITH   218-KENSINGTON-DETROIT-MI            2\n",
            "2          JOE DOE           SUNPHARMA-NOVI-MI            3\n",
            "3      PAT MUELLER  7650-ASHWOODPARK-DALLAS-TX            4\n",
            "4  PATRICK MUELLER  7650-ASHWOODPARK-DALLAS-TX            5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PjAT9YTCDkgT",
        "outputId": "fe174944-260a-4d75-f159-13c00bcf9031"
      },
      "source": [
        "#read nicknames csv file from below link\n",
        "#\"https://github.com/carltonnorthern/nickname-and-diminutive-names-lookup/blob/master/names.csv\"\n",
        "nick_df = pd.read_csv('https://raw.githubusercontent.com/lauracline/FuzzyWuzzy-Matching/master/Nicknames.csv', sep=',', header=0)\n",
        "print(nick_df.head())"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               Nicknames\n",
            "0  aaron,erin,ronnie,ron\n",
            "1     abbie,abby,abigail\n",
            "2      abe,abraham,abram\n",
            "3        abednego,bedney\n",
            "4   abel,ebbie,ab,abe,eb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8u6DcO7EZ4n"
      },
      "source": [
        "#update duplicate dictionary, keys are ID that is kept in final data\n",
        "#vals are list of dups discarded as result of comparision with key\n",
        "def update_dups(dupdict,keep,discard):\n",
        "    if keep[2]!=discard[2] and discard[2] in dupdict:\n",
        "        for id in dupdict[discard[2]]:\n",
        "            dupdict[keep[2]].append(id)\n",
        "        del dupdict[discard[2]]\n",
        "    dupdict[keep[2]].append(discard[2])\n",
        "    return dupdict"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViHrdMBMEQJU"
      },
      "source": [
        "#define new function called dups that discards duplicates of higher ID number and creates a seperate dataframe \n",
        "#final resemble data without duplicates\n",
        "#discarded consist duplicate records data\n",
        "def dups(final, discard, people, key, dupdict):\n",
        "    p1=people[0]\n",
        "    if len(people)>1:\n",
        "        iterpeople=people[1:]\n",
        "        for p2 in iterpeople:\n",
        "            if (p1[0] in inverse and p2[0] in inverse[p1[0]]) or (p2[0] in inverse and p1[0] in inverse[p2[0]]):\n",
        "                if p1[2]<=p2[2]:\n",
        "                    dupdict=update_dups(dupdict,p1,p2)\n",
        "                    discard.append([p2[1],key,p2[2]])\n",
        "                    people.remove(p2)\n",
        "                else:\n",
        "                    dupdict=update_dups(dupdict,p2,p1)\n",
        "                    discard.append([p1[1],key,p1[2]])\n",
        "                    return dups(final,discard,people[1:],key,dupdict)\n",
        "        final.append([p1[1],key,p1[2]])\n",
        "        if len(people)>1:\n",
        "            return dups(final,discard,people[1:],key,dupdict)\n",
        "        else:\n",
        "            return final, discard, dupdict\n",
        "    else:\n",
        "        final.append([p1[1],key,p1[2]])\n",
        "        return final, discard, dupdict"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S07q5sCrEmXL"
      },
      "source": [
        "#updates duplicate dictionary, keys are ID that is kept in final data \n",
        "#vals are list of dups discarded as result of comparision with key\n",
        "def update_fuzzy(dupdict,keep,discard):\n",
        "    if keep[1]!=discard[1] and discard[1] in dupdict:\n",
        "        for id in dupdict[discard[1]]:\n",
        "            dupdict[keep[1]].append(id)\n",
        "        del dupdict[discard[1]]\n",
        "    dupdict[keep[1]].append(discard[1])\n",
        "    return dupdict"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idYUyHHrEq2T"
      },
      "source": [
        "#define new function called dups that discards duplicates of higher ID number and creates a seperate dataframe \n",
        "#final resemble data without duplicates\n",
        "#discarded consist duplicate records data\n",
        "def fuzzydups(final, discard, people, key, dupdict):\n",
        "    p1=people[0]\n",
        "    if len(people)>1:\n",
        "        iterpeople=people[1:]\n",
        "        for p2 in iterpeople:\n",
        "            if fuzz.token_set_ratio(p1[0],p2[0]) > 80:\n",
        "                if p1[1]<=p2[1]:\n",
        "                    dupdict=update_fuzzy(dupdict,p1,p2)\n",
        "                    discard.append([p2[0],key,p2[1]])\n",
        "                    people.remove(p2)\n",
        "                else:\n",
        "                    dupdict=update_fuzzy(dupdict,p2,p1)\n",
        "                    discard.append([p1[0],key,p1[1]])\n",
        "                    return fuzzydups(final,discard,people[1:],key,dupdict)\n",
        "        final.append([p1[0],key,p1[1]])\n",
        "        if len(people)>1:\n",
        "            return fuzzydups(final,discard,people[1:],key,dupdict)\n",
        "        else:\n",
        "            return final, discard, dupdict\n",
        "    else:\n",
        "        final.append([p1[0],key,p1[1]])\n",
        "        return final, discard, dupdict"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-UWo6soD02v",
        "outputId": "6b0baa14-b8a6-413f-eafe-88da80ff69da"
      },
      "source": [
        "#create dict from nickname csv\n",
        "start_time = time.time() \n",
        "\n",
        "d={}\n",
        "for index, row in nick_df.iterrows():\n",
        "    s=row[0].split(',')\n",
        "    d[s[0]]=s[1:]\n",
        "    \n",
        "    \n",
        "#invert dictionary so that nicknames are keys\n",
        "inverse=dict()\n",
        "for key in d:\n",
        "    for val in d[key]:\n",
        "        if val not in inverse:\n",
        "            inverse[val]=[key]\n",
        "        else:\n",
        "            inverse[val].append(key)\n",
        "            \n",
        "\n",
        "#create dict from address to list of customers for nickname matching                    \n",
        "testdict={}\n",
        "for index,row in df.iterrows():\n",
        "    if row[1] not in testdict:\n",
        "        testdict[row[1]]=[[row[0].split(' ')[0].lower(),row[0],row[2]]]\n",
        "    else:\n",
        "        testdict[row[1]].append([row[0].split(' ')[0].lower(),row[0],row[2]])       \n",
        "\n",
        "\t\t\n",
        "#run nickname matching\n",
        "final=[]\n",
        "discarded=[]\n",
        "dupdict = collections.defaultdict(list)\n",
        "for key,val in testdict.items():\n",
        "    people=list(val)\n",
        "    f,d,dupdict=dups([],[],people,key,dupdict)\n",
        "    final+=f\n",
        "    discarded+=d\n",
        "newdf=pd.DataFrame(final, columns=['NAME', 'KEY', 'CUST_MSTR_ID'])\n",
        "dropped=pd.DataFrame(discarded, columns=['NAME', 'KEY', 'CUST_MSTR_ID'])\n",
        "\n",
        "\n",
        "\n",
        "fuzzydict={}\n",
        "for index,row in newdf.iterrows():\n",
        "    if row[1] not in fuzzydict:\n",
        "        fuzzydict[row[1]]=[[row[0],row[2]]]\n",
        "    else:\n",
        "        fuzzydict[row[1]].append([row[0],row[2]])\n",
        "\n",
        "\t\t\n",
        "#run fuzzy matching\n",
        "fuzzyfinal=[]\n",
        "fuzzydiscard=[]\n",
        "for key,val in fuzzydict.items():\n",
        "    people=list(val)\n",
        "    f,d,dupdict=fuzzydups([],[],people,key,dupdict)\n",
        "    fuzzyfinal+=f\n",
        "    fuzzydiscard+=d\n",
        "fuzzydf=pd.DataFrame(fuzzyfinal, columns=['NAME', 'KEY', 'CUST_MSTR_ID'])\n",
        "fuzzydropped=pd.DataFrame(fuzzydiscard, columns=['NAME', 'KEY', 'CUST_MSTR_ID'])\n",
        "\n",
        "print(\"My program took\", time.time() - start_time, \"to run\") "
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "My program took 0.08842754364013672 to run\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrgxeh2ZEvMu"
      },
      "source": [
        "#combine records dropped in nickname/fuzzy matching\n",
        "alldropped=pd.concat([dropped,fuzzydropped], ignore_index=True)\n",
        "\n",
        "#add column to final data with all duplicate IDs for row     \n",
        "l=[]\n",
        "for index, row in fuzzydf.iterrows():\n",
        "    if row[2] in dupdict:\n",
        "        l.append(dupdict[row[2]])\n",
        "    else:\n",
        "        l.append([])\n",
        "fuzzydf['DUPLICATE_IDS']=pd.Series(l)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ld4ppwnbEy6Z"
      },
      "source": [
        "#save file with final data after fuzzy matching\n",
        "writer = pd.ExcelWriter('fuzzy_final.xlsx', engine='xlsxwriter')\n",
        "fuzzydf.to_excel(writer, index=False)\n",
        "writer.save()\n",
        "\n",
        "#save file with all dropped IDs\n",
        "writer = pd.ExcelWriter('drop_final.xlsx', engine='xlsxwriter')\n",
        "alldropped.to_excel(writer, index=False)\n",
        "writer.save()"
      ],
      "execution_count": 31,
      "outputs": []
    }
  ]
}